<head>

  <script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>


  <!-- Include latest jquery.scrollTo, can download from https://github.com/flesler/jquery.scrollTo/releases -->
  <script type="text/javascript" src="//cdn.jsdelivr.net/jquery.scrollto/2.1.2/jquery.scrollTo.min.js"></script>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title> Tutorials | Demo</title>
  <meta name="description" content="A showcase of Simply Docs by MarketingPipeline built using Simple.CSS">

  <link rel="stylesheet" href="./../assets/style.css">



  <link rel="icon" href="./../assets/images/favicon.png">
  <link rel="apple-touch-icon" href="./../assets/images/favicon.png">


  <!-- Facebook integration -->
  <meta property="og:title" content="Simply Docs Demo">
  <meta property="og:image" content="./../assets/images/OG_image.png">
  <meta property="og:url" content="https://marketingpipeline.github.io/Simply-Docs/">
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Simple.css">
  <meta property="og:description" content="A Simply Docs / Blog Template built using Simple.css.">

  <!-- Twitter integration -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Simply Docs | Demo">
  <meta name="twitter:image" content="./../assets/images/OG_image.png">
  <meta name="twitter:url" content="https://marketingpipeline.github.io/Simply-Docs/">
  <meta name="twitter:description" content="A Simply Docs / Blog Template built using Simple.css">


  <script src="https://cdn.jsdelivr.net/npm/prismjs@1.28.0/prism.min.js"></script>

</head>
<header>
  <nav>

    <a href="./../index.html">Home</a>

    <a href="./../pages/documentation.html">Tutorials</a>

    <a href="https://github.com/bc-cv"><svg class="icon" viewBox="0 0 32 32">
        <path
          d="M16 0.395c-8.836 0-16 7.163-16 16 0 7.069 4.585 13.067 10.942 15.182 0.8 0.148 1.094-0.347 1.094-0.77 0-0.381-0.015-1.642-0.022-2.979-4.452 0.968-5.391-1.888-5.391-1.888-0.728-1.849-1.776-2.341-1.776-2.341-1.452-0.993 0.11-0.973 0.11-0.973 1.606 0.113 2.452 1.649 2.452 1.649 1.427 2.446 3.743 1.739 4.656 1.33 0.143-1.034 0.558-1.74 1.016-2.14-3.554-0.404-7.29-1.777-7.29-7.907 0-1.747 0.625-3.174 1.649-4.295-0.166-0.403-0.714-2.030 0.155-4.234 0 0 1.344-0.43 4.401 1.64 1.276-0.355 2.645-0.532 4.005-0.539 1.359 0.006 2.729 0.184 4.008 0.539 3.054-2.070 4.395-1.64 4.395-1.64 0.871 2.204 0.323 3.831 0.157 4.234 1.026 1.12 1.647 2.548 1.647 4.295 0 6.145-3.743 7.498-7.306 7.895 0.574 0.497 1.085 1.47 1.085 2.963 0 2.141-0.019 3.864-0.019 4.391 0 0.426 0.288 0.925 1.099 0.768 6.354-2.118 10.933-8.113 10.933-15.18 0-8.837-7.164-16-16-16z">
        </path>
      </svg>Github</a>

  </nav>

  <h1>Tutorials</h1>
  <p>Detailed tutorials for our anotation tools.</p>
</header>



<main>
  <fieldset>
    <!--
        Every fieldset must contain a legend. IE barfs if it's not there.
        It's no fun.
        -->
    <legend>Table Of Contents</legend>


    <ul>
      <li><a href="#about1"><b>Initial Tool</a></b>
        <ul>
          <li><a href="#info_1">The Data</a></li>
          <li><a href="#info_2">Creating and Using the annotation portal</a></li>
          <li><a href="#tut_1">Video Tutorial for using the tool</a></li>
        </ul>
    </ul>
    <ul>
      <li><a href="#about2"><b>Classwise Annotation Tool</a></b>
        <ul>
          <li><a href="#info_3">Setting up the tool</a></li>
          <li><a href="#info_4">Working with the tool</a></li>
          <li><a href="#tut_2">Video Tutorial for using the tool</a></li>
        </ul>



  </fieldset>



  <article>
    <h1 id="about1">Initial Tool</h1>
    <h3 id="info_1">The Data</h3>
    <p>
      The data consists of video frames where the subjects (children) are recorded trying to touch and feel different
      solid shapes, using hand gestures. The task is to identify the start and end frames of a single attempt by the
      subject (shot). The activity may be repeated several times for identifying a single shape (trial), using different
      strategies each time. The following schematic helps to understand our usage of the terms "shot" and "trial".
    </p>
    <center><img src="./../assets/images/video_anatomy.gif" height="" width="" alt="This is a random image caption.">
    </center>

    <h3 id="info_2">Creating the annotation portal</h3>
    <p>
    <ul>
      <li>Install the ImUtil library using the following:
        <code>
          <pre>
    pip install git+https://github.com/donglaiw/ImUtil.git
          </pre>
        </code>
      </li>
      <li>Import libraries as:
        <code>
          <pre>
    import cv2
    from imu.video.Basic_Shot_Detection import Shot_detect
          </pre>
        </code>
      </li>
      <li>Import libraries as:
        <code>
          <pre>
    path = '/path/to/frame/directory/'
    S = Shot_detect(path)
    S.set_thresholds([12,130,30,22,220,120],[13,60,100,20,140,240]) #The numbers are thresholds for rough hand and
    shadow segmentation
    S.set_crop_indices()
    S.extract_features()
    S.detect_shots(0.15,0.6, showPlot=False) #setting showPlot as True displays a plot for features detected and
    the shot separations made
          </pre>
        </code>
      </li>
    </ul>
    </p>

    <h3 id="tut_1">Video Tutorial for using the tool</h3>
    <p>We have presented a video tutorial for easier understanding of the usage of the tool.</p>
    <center>
      <video controls>
        <source src="./../assets/images/shot_detect_tool.mp4" type="video/mp4">
      </video>
    </center>

  </article>
  <footer>
  </footer>

  <article>
    <h1 id="about2">Classwise Annotation Tool</h1>
    <p>
      We have developed a Google Colab based shot annotation tool for the task of hand gesture annotations. While the
      application is highly specific to the UMB Hand Videos, the tool and the data setup can be easily modified for use
      in other kinds of video data. The tool can be found <a
        href="https://colab.research.google.com/drive/1dHl6qAFwzoWySEryXq49M7f--glJWH53?usp=sharing" target="_blank"
        rel="noopener noreferrer">here</a>.
    </p>

    <h3 id="info_3">Setting up the tool</h3>
    <p>
      The tool primarily operates in a Google Drive environment, which uses a linux based file manager. The video shot
      data in a separated format, along with the initial labels is available in the "/label" directory which should be
      added to your Google Drive as a shortcut as "/content/drive/MyDrive/label" . In order to obtain the "/label"
      directory for the data, please contact the authors as this data can only be shared upon request.
    </p>

    <h3 id="info_4">Working with the tool</h3>
    <p>
      We have provided an extensive video tutorial in the following section. <i>Libraries and Preliminaries</i> section
      needs to be run as it is with the "dev mode" checkbox is unchecked. The annotation tool identifies the annotators
      and their work using their specific usernames, so it is recommended that the same username be used in both code
      blocks of the <i>Settings</i> section.
    </p>

    <p>
      Finally, in the <i>Review</i> section, choose the hand side and class to annotate. This shows the shots that have
      been initially labelled as a certain class (as chosen by the user), but requires a review to assess the quality of
      annotation. The review section uses a command user interface to operate. The commands, their utilities and some
      use cases have been discussed in the following list.
    </p>

    <p>
    <ul>
      <li><b>The Start and Stop Commands</b>(<i>st</i> and <i>stp</i>): Upon running the <i>Command Line for Review</i>
        a text box appears as shown in the figure. In order to start the reviewing procedure, enter
        command st and immediately a prompt appears before the next command line, as shown in the
        next figure. The prompt "(5/27)>>>" in the figure below indicates the shot number the pointer
        is at currently. For example if you wish to start at a specific shot number that you remember,
        you may use that start command as: st 32 assuming you wish to start at the shot number 32
        (Here, 32 is the argument to the command <i>st</i>). In order to stop reviewing, simply use the
        command stp (no arguments) and press Enter.</li>
      <li><b>The Move Pointer Command</b>(<i>mov</i>): The mov command can be used to move the pointer by
        one shot. This command may or may not have any arguments depending on how you wish to
        use it. This is useful if you have finished working on one shot and with to work on the next
        shot. Simply write mov in the command line and press Enter and the prompt increments by 1
        place. If you wish to increment the pointer place by more than one places, say 5 places, you can
        do this by simply adding an argument to the command as: mov 5. In order to move to the
        previous shot again, use the command mov -1.</li>
      <li> <b>The Show GIF Command and Changing GIF frame-rate</b> (<i>show</i> and <i>fps</i>): Unlike the
        previous tool, the review tool does not display the GIFs by default. GIFs can now be viewed by
        entering the command show (no arguments) in the command line and pressing Enter. The
        default frame rate of the GIFs is 5 frames per second (fps). In case you need to slow the GIFs
        down and view them, you can do this by using the command: fps 2. This command will set the
        fps of the GIFs to 2 frames per second. Now if you re-input the command show, you can view
        the slowed down GIF. The argument of the fps command can be set according to you
        requirement.</li>
      <li> <b>The Edit Score and Edit Label Commands</b> (<i>ed_score</i> and <i>ed_label</i>): In order to edit the
        previously assigned Confidence score that has been displayed by the show command, you can
        edit the score using the command: ed_score 2 (if you wish to change the score to 2. Arguments
        can only be in the range: [1,2,3] i.e. the 3-point scale of the confidence scores). In order to
        change the assigned label of the shot, you can do it very similarly using the command: ed_label
        4 (if you wish to change the label to class 4. Arguments can only be in the range: [1,2,3,4,5,6,7]
        i.e. the classes in the dataset). Please note that both these commands autosaves the scores and
        labels, but should you wish to manually save them, you may do so by simply using the
        command: save (no arguments).</li>
      <li> <b>The Split and Label Command</b> (<i>split_label</i>): In order to split a GIF into two or more parts and
        specify a label for each part, you can use the split_label command. We describe the usage of
        this command using the following use case, since the order of the arguments for this command
        can be a little confusing. This is the only command in our tool that can accommodate multiple
        arguments separated by a single space. Let us assume a GIF has 27 frames with the frames
        numbered as [1,2,3…26,27], and we wish to split the frames into 3 parts: [1-8], [9-20] and [21-
        27]. We therefore, can identify 2 split-points when such a split is made, which are at frame 8
        and frame 20. Now, let the labels for the parts be assigned as: Class 4 for [1-8], Class 2 for [9-
        20] and Class 5 for [21-27]. Therefore, the order in which the command arguments are placed
        is: 'label - splitpoint - label - splitpoint - ...' so on, for as many splits required. Specifically
        for our use case, the command can be called as: split_label 4 8 2 20 5. This command too has
        an autosave feature as soon as you call the command. In order to view the GIF in the split
        format, use the command: split_show and press Enter. Please note that split_show has no
        arguments and it can only be used if a certain GIF has been split before.</li>
    </ul>
    </p>
    <center><img src="./../assets/images/split_lab.PNG" height="" width="" alt="This is a random image caption.">
    </center>

    <h3 id="tut_2">Video Tutorial for using the tool</h3>
    <p>Here is a video demonstration of the tool in use. (Sorry for the occasional interruptions, although in a way, it
      does demonstrate the various use cases).</p>
    <center>
      <video controls>
        <source src="./../assets/images/vid2.mp4" type="video/mp4">
      </video>
    </center>


  </article>




</main>






<footer>
  <p>The Documentations were prepared by <a href="https://github.com/rB080">Rajarshi Bhattacharya</a> and <a
      href="https://github.com/Ruxie189">Rukhshanda Hussain</a> and is based heavily on the implementation by <a
      href="https://github.com/MarketingPipeline/Simply-Docs">Simply Docs</a>.</p>
  <small>© 2023 BC-CV</small>
  <!-- <address>email@email.com</address> -->
</footer>








<!-- Cool scroll effect from this guy: https://gist.github.com/flesler/ -->
<script>
  // Bind to the click of all links with a #hash in the href
  $('a[href^="#"]').click(function (e) {
    // Prevent the jump and the #hash from appearing on the address bar
    e.preventDefault();
    // Scroll the window, stop any previous animation, stop on user manual scroll
    // Check https://github.com/flesler/jquery.scrollTo for more customizability
    $(window).stop(true).scrollTo(this.hash, { duration: 500, interrupt: false });
  });
</script>

<script src="https://cdn.jsdelivr.net/gh/MarketingPipeline/Markdown-Tag/markdown-tag-commonmark.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js"
  integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
<script>anchors.add();</script>